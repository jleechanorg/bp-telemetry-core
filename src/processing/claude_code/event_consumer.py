# Copyright Â© 2025 Sierra Labs LLC
# SPDX-License-Identifier: AGPL-3.0-only
# License-Filename: LICENSE

"""
Claude Code Event Consumer.

Processes Claude Code telemetry events from Redis Streams.
Handles JSONL and transcript events, writes to claude_raw_traces table,
and publishes CDC events for slow path workers.
"""

import json
import logging
import time
from typing import Dict, List, Any, Optional
from collections import deque
import redis

from ..common.batch_manager import BatchManager
from ..common.cdc_publisher import CDCPublisher
from .raw_traces_writer import ClaudeRawTracesWriter
from ...capture.shared.redis_streams import (
    TELEMETRY_MESSAGE_QUEUE_STREAM,
    TELEMETRY_DLQ_STREAM,
)

logger = logging.getLogger(__name__)


class ClaudeEventConsumer:
    """
    High-throughput consumer for Claude Code events.

    Processes events from Redis Streams and writes to claude_raw_traces table.
    Target: <10ms per batch at P95.

    Features:
    - Redis Streams XREADGROUP for consumer groups
    - Batch accumulation (100 events or 100ms timeout)
    - SQLite batch writes with zlib compression
    - CDC event publishing for slow path workers
    - Dead Letter Queue (DLQ) for failed messages
    - Pending Entries List (PEL) retry handling

    Claude-specific handling:
    - JSONL monitor events
    - Transcript monitor events
    - Session lifecycle events
    """

    def __init__(
        self,
        redis_client: redis.Redis,
        claude_writer: ClaudeRawTracesWriter,
        cdc_publisher: CDCPublisher,
        stream_name: str = TELEMETRY_MESSAGE_QUEUE_STREAM,
        consumer_group: str = "processors",
        consumer_name: str = "claude-consumer-1",
        batch_size: int = 100,
        batch_timeout: float = 0.1,
        block_ms: int = 1000,
        max_retries: int = 3,
    ):
        """
        Initialize Claude event consumer.

        Args:
            redis_client: Redis client instance
            claude_writer: Claude raw traces writer
            cdc_publisher: CDC publisher
            stream_name: Redis Stream name
            consumer_group: Consumer group name
            consumer_name: Consumer name (unique per instance)
            batch_size: Maximum batch size
            batch_timeout: Batch timeout in seconds
            block_ms: Blocking timeout for XREADGROUP (ms)
            max_retries: Maximum retries before DLQ
        """
        self.redis_client = redis_client
        self.claude_writer = claude_writer
        self.cdc_publisher = cdc_publisher
        self.stream_name = stream_name
        self.consumer_group = consumer_group
        self.consumer_name = consumer_name
        self.batch_manager = BatchManager(batch_size, batch_timeout)
        self.block_ms = block_ms
        self.max_retries = max_retries
        self.running = False
        self.dlq_stream = TELEMETRY_DLQ_STREAM
        
        # Backpressure handling
        self.current_batch_size = batch_size  # Adaptive batch size
        self.min_batch_size = 10  # Minimum batch size
        self.max_batch_size = batch_size  # Maximum batch size
        self.write_times = deque(maxlen=100)  # Track write latencies for backpressure
        self.pending_retry_idle_ms = max(int(batch_timeout * 1000), 100)

    def _ensure_consumer_group(self) -> None:
        """Ensure consumer group exists, create if not."""
        try:
            self.redis_client.xgroup_create(
                self.stream_name,
                self.consumer_group,
                id="0",
                mkstream=True
            )
            logger.info(f"Created consumer group {self.consumer_group}")
        except redis.ResponseError as e:
            if "BUSYGROUP" in str(e):
                # Group already exists, that's fine
                logger.debug(f"Consumer group {self.consumer_group} already exists")
            else:
                raise

    def _decode_stream_message(self, message_id: str, fields: Dict[Any, Any]) -> Optional[Dict[str, Any]]:
        """
        Decode Redis Stream fields into an event dictionary.

        Args:
            message_id: Redis Stream message ID
            fields: Raw fields returned by Redis

        Returns:
            Event dictionary or None if decoding failed
        """
        try:
            event: Dict[str, Any] = {}

            for key, value in fields.items():
                key_str = key.decode("utf-8") if isinstance(key, bytes) else str(key)
                if isinstance(value, bytes):
                    val_str = value.decode("utf-8")
                else:
                    val_str = str(value)

                if key_str in ("payload", "metadata"):
                    try:
                        event[key_str] = json.loads(val_str)
                    except json.JSONDecodeError:
                        event[key_str] = {}
                else:
                    event[key_str] = val_str

            if "event_id" not in event:
                event["event_id"] = message_id
            if "session_id" not in event:
                event["session_id"] = event.get("external_session_id", "")

            return event
        except Exception as exc:
            logger.error(f"Failed to parse event from message {message_id}: {exc}")
            return None

    def _read_pending_messages(self, count: int = 100) -> List[Dict[str, Any]]:
        """
        Read pending messages that are already assigned to this consumer.
        
        Uses XREADGROUP with "0" to read messages from PEL that belong to this consumer.
        
        Args:
            count: Maximum number of messages to read
            
        Returns:
            List of message dictionaries with 'id' and 'event' keys
        """
        try:
            # Read pending messages assigned to this consumer using "0"
            # "0" means read from PEL (Pending Entries List) for this consumer
            messages = self.redis_client.xreadgroup(
                self.consumer_group,
                self.consumer_name,
                {self.stream_name: "0"},
                count=count,
                block=0  # Non-blocking read
            )

            if not messages:
                return []

            # Parse messages
            result = []
            for stream_name, stream_messages in messages:
                for message_id, fields in stream_messages:
                    # Convert message_id to string
                    msg_id = message_id.decode('utf-8') if isinstance(message_id, bytes) else str(message_id)
                    event = self._decode_stream_message(msg_id, fields)
                    result.append({
                        'id': msg_id,
                        'event': event
                    })

            return result

        except redis.ConnectionError as e:
            logger.error(f"Redis connection error reading pending: {e}")
            return []
        except Exception as e:
            logger.error(f"Error reading pending messages: {e}")
            return []

    def _read_messages(self) -> List[Dict[str, Any]]:
        """
        Read messages from Redis Streams using XREADGROUP.

        Returns:
            List of message dictionaries with 'id' and 'event' keys
        """
        try:
            # Read from stream with consumer group
            messages = self.redis_client.xreadgroup(
                self.consumer_group,
                self.consumer_name,
                {self.stream_name: ">"},
                count=self.current_batch_size,
                block=self.block_ms
            )

            if not messages:
                return []

            # Parse messages
            result = []
            for stream_name, stream_messages in messages:
                for message_id, fields in stream_messages:
                    # Convert message_id to string
                    msg_id = message_id.decode('utf-8') if isinstance(message_id, bytes) else str(message_id)
                    event = self._decode_stream_message(msg_id, fields)
                    result.append({
                        'id': msg_id,
                        'event': event
                    })

            return result

        except redis.ConnectionError as e:
            logger.error(f"Redis connection error: {e}")
            return []
        except Exception as e:
            logger.error(f"Error reading messages: {e}")
            return []

    def _process_batch(self, messages: List[Dict[str, Any]]) -> List[str]:
        """
        Process batch of Claude Code messages.

        Filters for Claude Code events, writes to claude_raw_traces table,
        and publishes CDC events. ACKs messages immediately after successful write.

        Args:
            messages: List of message dictionaries from Redis Stream

        Returns:
            List of message IDs that were successfully processed
        """
        if not messages:
            return []

        # Extract events (skip None events from parse errors)
        events = []
        valid_message_ids = []

        for msg in messages:
            if msg['event'] is not None:
                event = msg['event']
                events.append(event)
                valid_message_ids.append(msg['id'])
            else:
                # Invalid event - send to DLQ immediately
                logger.warning(f"Invalid event (None) for message {msg['id']}, sending to DLQ")
                self._handle_failed_message(msg['id'], msg.get('event'), retry_count=self.max_retries)

        if not events:
            logger.debug("No valid events to process in batch")
            return []

        try:
            # Filter Claude Code events
            claude_events = []

            for event, msg_id in zip(events, valid_message_ids):
                platform = event.get('platform', '')
                if platform == 'claude_code':
                    # Include JSONL/transcript events AND session lifecycle events
                    source = event.get('metadata', {}).get('source', '')
                    hook_type = event.get('hook_type', '')
                    event_type = event.get('event_type', '')

                    # Include events from JSONL/transcript monitors AND session lifecycle events
                    if (source in ('jsonl_monitor', 'transcript_monitor') or
                        hook_type == 'JSONLTrace' or
                        event_type in ('session_start', 'session_end')):
                        claude_events.append(event)
                    else:
                        # Skip non-essential hook events
                        logger.debug(f"Skipping Claude Code hook event: {hook_type or event_type}")
                else:
                    # Skip non-Claude events (they should be handled by platform-specific consumers)
                    logger.debug(f"Skipping non-Claude event with platform={platform}")

            # Write Claude Code events to claude_raw_traces table
            start_time = time.time()
            all_sequences = []
            all_events = []

            if claude_events:
                claude_sequences = self.claude_writer.write_batch_sync(claude_events)
                all_sequences.extend(claude_sequences)
                all_events.extend(claude_events)
                logger.debug(f"Wrote {len(claude_events)} Claude Code events to claude_raw_traces")

            write_duration = time.time() - start_time

            # Track write latency for backpressure
            self.write_times.append(write_duration)

            # Publish CDC events
            for sequence, event in zip(all_sequences, all_events):
                self.cdc_publisher.publish(sequence, event)

            logger.debug(f"Processed batch: {len(claude_events)} Claude Code events, duration: {write_duration:.3f}s")

            # ACK messages immediately after successful write
            self._ack_messages(valid_message_ids)

            return valid_message_ids

        except Exception as e:
            logger.error(f"Failed to process batch: {e}", exc_info=True)
            # Don't ACK messages - they'll retry via PEL
            return []

    def _ack_messages(self, message_ids: List[str]) -> None:
        """
        Acknowledge processed messages.

        Args:
            message_ids: List of message IDs to acknowledge
        """
        if not message_ids:
            return

        try:
            self.redis_client.xack(
                self.stream_name,
                self.consumer_group,
                *message_ids
            )
        except Exception as e:
            logger.error(f"Failed to ACK messages: {e}")

    def _handle_failed_message(self, message_id: str, event: Optional[Dict], retry_count: int) -> None:
        """
        Handle failed message: send to DLQ if max retries exceeded.

        Args:
            message_id: Message ID
            event: Event data (may be None)
            retry_count: Current retry count
        """
        if retry_count >= self.max_retries:
            # Send to Dead Letter Queue
            try:
                dlq_data = {
                    'message_id': message_id,
                    'retry_count': retry_count,
                    'event': json.dumps(event) if event else 'null',
                }
                self.redis_client.xadd(
                    self.dlq_stream,
                    dlq_data,
                    maxlen=1000,
                    approximate=True
                )
                logger.warning(f"Sent message {message_id} to DLQ after {retry_count} retries")
            except Exception as e:
                logger.error(f"Failed to send message to DLQ: {e}")

    def _adjust_batch_size(self) -> None:
        """
        Adjust batch size based on write latency (adaptive backpressure).
        
        If writes are slow, reduce batch size to prevent memory buildup.
        If writes are fast, increase batch size for better throughput.
        Updates both current_batch_size and batch_manager.batch_size.
        """
        if len(self.write_times) < 10:
            # Not enough data yet
            return
        
        # Calculate average write latency
        avg_latency = sum(self.write_times) / len(self.write_times)
        
        # Target latency: 10ms per batch
        target_latency = 0.010
        
        if avg_latency > target_latency * 2:
            # Writes are slow - reduce batch size
            new_size = max(
                self.min_batch_size,
                int(self.current_batch_size * 0.8)
            )
            if new_size != self.current_batch_size:
                self.current_batch_size = new_size
                self.batch_manager.batch_size = new_size
                logger.debug(f"Reduced batch size to {self.current_batch_size} (avg latency: {avg_latency:.3f}s)")
        elif avg_latency < target_latency * 0.5:
            # Writes are fast - increase batch size
            new_size = min(
                self.max_batch_size,
                int(self.current_batch_size * 1.1)
            )
            if new_size != self.current_batch_size:
                self.current_batch_size = new_size
                self.batch_manager.batch_size = new_size
                logger.debug(f"Increased batch size to {self.current_batch_size} (avg latency: {avg_latency:.3f}s)")

    def _should_throttle_reads(self) -> bool:
        """
        Check if we should throttle reads due to backpressure.
        
        Returns:
            True if reads should be throttled
        """
        # Throttle if batch manager is nearly full
        if self.batch_manager.size() >= self.max_batch_size * 0.9:
            return True
        
        # Throttle if recent writes are very slow
        if len(self.write_times) >= 5:
            recent_latencies = list(self.write_times)[-5:]
            avg_recent = sum(recent_latencies) / len(recent_latencies)
            if avg_recent > 0.050:  # 50ms average
                return True
        
        return False

    def _get_pending_count(self) -> int:
        """Get total count of pending messages in the consumer group."""
        try:
            pending_info = self.redis_client.xpending(self.stream_name, self.consumer_group)
            if isinstance(pending_info, (list, tuple)) and len(pending_info) >= 1:
                return int(pending_info[0])
            return 0
        except Exception as e:
            logger.debug(f"Failed to get pending count: {e}")
            return 0

    def _process_pending_messages(self) -> None:
        """Process pending messages from PEL (retry failed messages)."""
        try:
            # Get total pending count to determine batch size
            total_pending = self._get_pending_count()
            
            # If there's a large backlog, prioritize pending messages
            # Use batch size of 100 for pending messages
            pending_batch_size = 100
            
            # Get pending messages - check ALL messages in the group, not just this consumer
            # This allows us to claim messages from inactive consumers
            pending = self.redis_client.xpending_range(
                self.stream_name,
                self.consumer_group,
                min="-",
                max="+",
                count=pending_batch_size * 2,  # Get more to filter
            )

            if not pending:
                return

            # Log progress when processing large backlog
            if total_pending > 100:
                logger.info(f"Processing pending messages: {total_pending} total pending, batch size: {pending_batch_size}")

            retry_ids: List[str] = []
            dlq_candidates: Dict[str, int] = {}

            for entry in pending:
                message_id = entry.get('message_id')
                if not message_id:
                    continue

                # Redis-py returns message_id as string
                msg_id_str = str(message_id)
                delivery_count = entry.get('delivery_count', 0)
                idle_time_ms = entry.get('idle', 0)

                if delivery_count >= self.max_retries:
                    dlq_candidates[msg_id_str] = delivery_count
                elif idle_time_ms >= self.pending_retry_idle_ms:
                    retry_ids.append(msg_id_str)

            # Process larger batches when there's a backlog
            if retry_ids:
                retry_ids = retry_ids[:pending_batch_size]

            # First, move messages that exceeded retry limit to DLQ
            if dlq_candidates:
                try:
                    claimed_dlq = self.redis_client.xclaim(
                        self.stream_name,
                        self.consumer_group,
                        self.consumer_name,
                        min_idle_time=0,
                        message_ids=list(dlq_candidates.keys())
                    )
                except Exception as claim_error:
                    logger.error(f"Failed to claim DLQ candidates: {claim_error}")
                    claimed_dlq = []

                for msg_id, fields in claimed_dlq:
                    msg_id_str = msg_id.decode('utf-8') if isinstance(msg_id, bytes) else str(msg_id)
                    event = self._decode_stream_message(msg_id_str, fields)
                    retry_count = dlq_candidates.get(msg_id_str, self.max_retries)

                    self._handle_failed_message(msg_id_str, event, retry_count=retry_count)

                    try:
                        self.redis_client.xack(self.stream_name, self.consumer_group, msg_id_str)
                    except Exception as ack_error:
                        logger.error(f"Failed to ACK DLQ message {msg_id_str}: {ack_error}")

                    # Ensure duplicates aren't processed later
                    self.batch_manager.remove_message_ids([msg_id_str])

            # First, always try to read pending messages directly assigned to this consumer
            # This is the most efficient way to process them
            # But we need to check delivery_count to avoid processing messages that exceeded max_retries
            pending_direct = self._read_pending_messages(count=pending_batch_size)
            
            if pending_direct:
                # Build a map of message_id -> delivery_count from the pending info we already have
                # This avoids extra Redis calls
                pending_map = {str(entry.get('message_id')): entry.get('delivery_count', 0) 
                              for entry in pending if entry.get('message_id')}
                
                # Filter out messages that have exceeded max retries
                messages_to_process = []
                dlq_from_direct = []
                
                for msg in pending_direct:
                    delivery_count = pending_map.get(msg['id'], 0)
                    if delivery_count >= self.max_retries:
                        # This message exceeded max retries, send to DLQ
                        dlq_from_direct.append((msg['id'], msg['event'], delivery_count))
                    else:
                        messages_to_process.append(msg)
                
                # Send messages that exceeded retries to DLQ
                for msg_id, event, delivery_count in dlq_from_direct:
                    self._handle_failed_message(msg_id, event, retry_count=delivery_count)
                    try:
                        self.redis_client.xack(self.stream_name, self.consumer_group, msg_id)
                    except Exception as ack_error:
                        logger.error(f"Failed to ACK DLQ message {msg_id}: {ack_error}")
                    self.batch_manager.remove_message_ids([msg_id])
                
                # Process remaining messages
                if messages_to_process:
                    processed_ids = self._process_batch(messages_to_process)
                    if processed_ids:
                        self.batch_manager.remove_message_ids(processed_ids)
                        logger.info(f"Processed {len(processed_ids)} pending messages (direct read)")
                        # Remove processed IDs from retry_ids if they were in there
                        retry_ids = [msg_id for msg_id in retry_ids if msg_id not in processed_ids]
                    else:
                        logger.warning(f"Failed to process {len(messages_to_process)} pending messages (direct read)")

            # Reprocess pending messages that have been idle long enough (from other consumers or missed)
            if retry_ids:
                    try:
                        claimed_retry = self.redis_client.xclaim(
                            self.stream_name,
                            self.consumer_group,
                            self.consumer_name,
                            min_idle_time=self.pending_retry_idle_ms,
                            message_ids=retry_ids[:pending_batch_size]
                        )
                    except Exception as claim_error:
                        logger.error(f"Failed to claim retry messages: {claim_error}")
                        claimed_retry = []

                    if claimed_retry:
                        messages = []
                        for msg_id, fields in claimed_retry:
                            msg_id_str = msg_id.decode('utf-8') if isinstance(msg_id, bytes) else str(msg_id)
                            event = self._decode_stream_message(msg_id_str, fields)

                            if event is None:
                                # Unparseable event - send to DLQ immediately
                                self._handle_failed_message(msg_id_str, event, retry_count=self.max_retries)
                                try:
                                    self.redis_client.xack(self.stream_name, self.consumer_group, msg_id_str)
                                except Exception as ack_error:
                                    logger.error(f"Failed to ACK malformed message {msg_id_str}: {ack_error}")
                                self.batch_manager.remove_message_ids([msg_id_str])
                                continue

                            messages.append({'id': msg_id_str, 'event': event})

                        if messages:
                            processed_ids = self._process_batch(messages)
                            if processed_ids:
                                self.batch_manager.remove_message_ids(processed_ids)
                                logger.debug(f"Processed {len(processed_ids)} pending messages (claimed)")
                            else:
                                logger.warning(f"Failed to process {len(messages)} pending messages")
                    elif retry_ids:
                        logger.debug(f"Could not claim {len(retry_ids)} pending messages for retry")

        except Exception as e:
            logger.error(f"Error processing pending messages: {e}")

    def run(self) -> None:
        """
        Main Claude Code consumer loop.

        Continuously reads Claude Code events from Redis Streams,
        batches them, writes to claude_raw_traces table, and publishes CDC events.

        Features:
        - Filters for Claude Code platform events only
        - Synchronous SQLite writes with zlib compression
        - Immediate ACK after successful write (prevents message loss)
        - Backpressure handling (adaptive batch sizing, read throttling)
        """
        self.running = True
        self._ensure_consumer_group()

        logger.info(f"Claude Code event consumer started: {self.consumer_name}")

        iteration = 0
        while self.running:
            try:
                # Check pending message count - prioritize if backlog is significant
                pending_count = self._get_pending_count()
                
                # Process pending messages first (retries)
                # If there's a large backlog, process multiple batches before reading new messages
                if pending_count > 100:
                    # Process multiple batches of pending messages when backlog is large
                    for _ in range(min(5, pending_count // 50)):
                        self._process_pending_messages()
                        if self._get_pending_count() < 50:
                            break
                else:
                    self._process_pending_messages()

                # Adjust batch size based on write latency (backpressure)
                self._adjust_batch_size()

                # Throttle reads if we have too many pending batches
                if self._should_throttle_reads():
                    logger.debug("Throttling reads due to backpressure")
                    time.sleep(0.1)
                    continue

                # Only read new messages if pending backlog is manageable
                # This ensures we catch up on pending messages first
                if pending_count < 200:
                    # Read new messages
                    messages = self._read_messages()
                else:
                    # Skip reading new messages when backlog is large
                    messages = []
                    if iteration % 10 == 0:  # Log every 10 iterations when skipping
                        logger.info(f"Prioritizing pending messages: {pending_count} pending, skipping new reads")
                iteration += 1

                if messages:
                    # Add events to batch with their message IDs
                    for msg in messages:
                        if msg['event']:
                            ready = self.batch_manager.add_event(msg['event'], msg['id'])
                            if ready:
                                # Batch is full, get events and IDs
                                batch_events, batch_ids = self.batch_manager.get_batch()
                                
                                # Reconstruct messages with IDs
                                batch_messages = [
                                    {'id': msg_id, 'event': event}
                                    for event, msg_id in zip(batch_events, batch_ids)
                                ]
                                
                                # Process batch (includes immediate ACK)
                                processed_ids = self._process_batch(batch_messages)
                                if not processed_ids:
                                    logger.warning(f"Batch processing failed for {len(batch_messages)} messages")

                # Check if timeout-based flush is needed
                if self.batch_manager.should_flush() and not self.batch_manager.is_empty():
                    batch_events, batch_ids = self.batch_manager.get_batch()
                    if batch_events:
                        batch_messages = [
                            {'id': msg_id, 'event': event}
                            for event, msg_id in zip(batch_events, batch_ids)
                        ]
                        
                        processed_ids = self._process_batch(batch_messages)
                        if processed_ids:
                            self.batch_manager.remove_message_ids(processed_ids)

                # Small sleep to prevent tight loop
                time.sleep(0.01)

            except KeyboardInterrupt:
                logger.info("Consumer interrupted")
                break
            except Exception as e:
                logger.error(f"Error in consumer loop: {e}", exc_info=True)
                time.sleep(1)  # Back off on error

        logger.info("Claude Code event consumer stopped")

    def stop(self) -> None:
        """Stop the consumer."""
        self.running = False
